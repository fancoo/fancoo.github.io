<!DOCTYPE html>
<html lang="en">

<head>
    <title>Selected Samples of My Work</title>

    <link href="https://fonts.googleapis.com/css?family=Crimson+Text:400,400i" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:400,600" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="index.css">

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>

<body>

    <div class='section'>
        <h1>Samples</h1>
        <p>Audio/video samples from several <a href='https://www.linkedin.com/in/ringofang/'>Ke Fang</a>'s currently working projects.</i>.</p>

        <h4>Contents:</h4>
        <p>
        <ul class='toc'>
            <li><a href='#section-0'>Real-Time Baby Face Generation on Low-End Mobile Devices</a></li>
            <li><a href='#section-1'>MusicGAN: A Method For Long-Term Raw Piano Sentences Generation</a></li>
            <li><a href='#section-2'>Computation Efficient Single-Speaker TTS(Mandarin)</a></li>
            <li><a href='#section-3'>Speaker-Adaptation TTS</a></li>
            <li><a href='#section-4'>Speech-Conversion with VQ-VAE</a></li>
            <li><a href='#section-5'>One-shot Speech-Conversion</a></li>
            <!--<li><a href='#section-6'>Speeding up Griffin-Lim Vocoder & GAN-based TTS Optimization</a></li>-->
        </ul>
        </p>

        <h4>Notes:</h4>
        <p>
        <ul>
            <li>Due to privacy issue, I will not introduce the technical details of these projects, the purpose for this page is only to record some of my works.</li>
            <li>Audio clips which correspond to ground-truth data are generated by inverting ground-truth spectrograms.</li>
        </ul>
        </p>
    </div>

    <hr>

    <div id='section-0' class='section'>
        <h2>Mobile Real-time Baby Face Generation</h2>
        <ul>
            <li>Samples of our GAN-based magic sticker that runs on both high/low-end mobile devices among iOS and Android system.</li>
            <li>Over a million videos used it on Kuaishou(快手) app two days after this sticker is online.</li>
        </ul>
        <h3>Samples</h3>
        <p><img src="samples/gif/gan-a.gif" alt="gan-a"></p>
        <p><img src="samples/gif/gan-b.gif" alt="gan-a"><img src="samples/gif/gan-c.gif" alt="gan-a"></p>

    </div>

    <div id='section-1' class='section'>
        <h2>Long-Term Raw Piano Notes Generation</h2>
        <p>Samples from my MusicGAN project of unconditional raw Mozart's piano notes generation.</p>
        <p>This project tries to use GAN to learn long-term dependencies music generation, which is a main defect of current GAN-based sound art.</p>

        <h3>Samples</h3>
        <p>Samples generated from random z without any condition.</p>
        <div class='playlist'>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/wav/music_gan_piano/1.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/wav/music_gan_piano/2.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/wav/music_gan_piano/3.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/wav/music_gan_piano/4.mp3' type='audio/mpeg'></audio></div>
        </div>
    </div>

    <hr>

    <div id='section-2' class='section'>
        <h2>Computation Efficient Single-Speaker TTS(Mandarin)</h2>
        <p>Samples generated by my modified Tacotron based TTS trained on ~20h Mandarin Chinese single-speaker dataset. The model can run on mobile devices in real-time.</p>
        <h3>Samples</h3>
        <p>Samples from my TTS model, sentences below are randomly chosen from zhihu.com.</p>
        <div class='playlist'>
            <p class='playlist-title text'>&ldquo;感谢您选购世纪佳缘网，我们将为您提供优质的服务和放心的产品。&rdquo;</p>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/wav/single_speaker_tts_mandarin/1.wav' type='audio/mpeg'></audio></div>
            <p class='playlist-title text'>&ldquo;“中国氢弹之父”于敏，于1月16日在京去世，享年93岁。于敏毕业于北京大学，后被著名物理学家钱三强、彭桓武调到中科院近代物理研究所。&rdquo;</p>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/wav/single_speaker_tts_mandarin/2.wav' type='audio/mpeg'></audio></div>
            <p class='playlist-title text'>&ldquo;我看了整场发布会，感觉抖音这家公司或者说今日头条这家公司真的是有一些精神分裂。&rdquo;</p>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/wav/single_speaker_tts_mandarin/3.wav' type='audio/mpeg'></audio></div>
            <p class='playlist-title text'>&ldquo;岳云鹏的相声经常性的在台上中断表演，针对某个观众说一些态度比较激烈的话。&rdquo;</p>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/wav/single_speaker_tts_mandarin/4.wav' type='audio/mpeg'></audio></div>
            <p class='playlist-title text'>&ldquo;作为一个正在进行时的舔狗，我感觉我有必要在这里宣泄释放一下，文字表达能力有限，反正就这样吧&rdquo;</p>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/wav/single_speaker_tts_mandarin/5.wav' type='audio/mpeg'></audio></div>
        </div>
    </div>

    <hr>

    <div id='section-3' class='section'>
        <h2>Speaker-Adaptation TTS</h2>
        <p>Samples of using Multi-Speaker TTS model for Speaker-Adaptation. We trained the model on ~800 speakers TTS, then collect ~1min new speakers audio for adaption, below is the results on two famous voices.</p>

        <h3>Samples</h3>
        <p>Samples of Guo Degang(郭德纲) and Chibi Maruko-chan(樱桃小丸子(国语版)).</p>
        <div class='playlist'>
            <p class='playlist-title text'>&ldquo;想要带你去浪漫的土耳其。&rdquo;</p>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/wav/multi_speaker_tts_speaker_adaptation/gdg_0.wav' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/wav/multi_speaker_tts_speaker_adaptation/xwz_0.wav' type='audio/mpeg'></audio></div>
            <p class='playlist-title text'>&ldquo;海中月是天上月。&rdquo;</p>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/wav/multi_speaker_tts_speaker_adaptation/gdg_1.wav' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/wav/multi_speaker_tts_speaker_adaptation/xwz_1.wav' type='audio/mpeg'></audio></div>
            <p class='playlist-title text'>&ldquo;亲爱的李岩倪，我是你最喜爱的郭德纲老师。&rdquo;</p>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/wav/multi_speaker_tts_speaker_adaptation/gdg_2.wav' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/wav/multi_speaker_tts_speaker_adaptation/xwz_2.wav' type='audio/mpeg'></audio></div>
            <p class='playlist-title text'>&ldquo;阿倪姐姐我是樱桃小丸子，旁嘎思密达！。&rdquo;</p>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/wav/multi_speaker_tts_speaker_adaptation/gdg_3.wav' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/wav/multi_speaker_tts_speaker_adaptation/xwz_3.wav' type='audio/mpeg'></audio></div>
        </div>
    </div>

    <hr>

    <div id='section-4' class='section'>
        <h2>Speech-Conversion with VQ-VAE</h2>
        <p>Samples generated by my implementation of paper <a href="https://arxiv.org/abs/1711.00937">Neural Discrete Representation Learning(VQ-VAE)</a> on the task of voice-style transfer with VCTK dataset.</p>

        <h3>Samples</h3>
        <p>The left audio is ground-truth, the right is the results.</p>

        <div class='playlist'>
            <p class='playlist-title text'>&ldquo;We are encouraged by the news.&rdquo;</p>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/wav/vqvae_audio/p227_363.wav' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/wav/vqvae_audio/p227_363_to_p231.wav' type='audio/mpeg'></audio></div>
            <p class='playlist-title text'>&ldquo;It was a breathtaking moment.&rdquo;</p>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/wav/vqvae_audio/p231_430.wav' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/wav/vqvae_audio/p231_430_to_p227.wav' type='audio/mpeg'></audio></div>
            <p class='playlist-title text'>&ldquo;Who was the mystery MP?&rdquo;</p>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/wav/vqvae_audio/p240_341.wav' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/wav/vqvae_audio/p240_341_to_p227.wav' type='audio/mpeg'></audio></div>
            <p class='playlist-title text'>&ldquo;Under Alex Ferguson, Aberdeen showed it could be done.&rdquo;</p>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/wav/vqvae_audio/p243_359.wav' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/wav/vqvae_audio/p243_359_to_p231.wav' type='audio/mpeg'></audio></div>
        </div>
    </div>

    <hr>

    <div id='section-5' class='section'>
        <h2>One-shot Speech-Conversion</h2>
        <p>Samples generated by my open-source repo <a href="https://github.com/mazzzystar/randomCNN-voice-transfer">randomCNN-voice-transfer</a>.</p>

        <h3>Samples</h3>
        <p>TBD</p>
        <!--
        <p>Samples generated by the model conditioned on text and speaker ID.  The conditioning text and speaker IDs are taken directly from the validation set (text in the dataset is unnormalized and unpunctuated).</p>
        <div class='playlist'>
            <div class='labeled-audio labeled-audio2'><p class='text text2'>it wasn't like i was asking for the code to a nuclear bunker or anything like that but the amount of resistance i got from this</p>
                <audio preload='metadata' controls><source class='select-real' src='samples/mp3/ted_val/sample-0.mp3' type='audio/mpeg'></audio>
            </div>

            <div class='labeled-audio labeled-audio2'><p class='text text2'>and what that form is modeling and shaping is not cement</p>
                <audio preload='metadata' controls><source class='select-real' src='samples/mp3/ted_val/sample-1.mp3' type='audio/mpeg'></audio>
            </div>
        </div>

        <div class='playlist'>
            <div class='labeled-audio'><p class='text'>A cramp is no small danger on a swim.</p>
                <audio preload='metadata' controls><source class='select-speaker' src='samples/mp3/ted_speakers/BillGates/sample-0.mp3' type='audio/mpeg'></audio>
            </div>
            <div class='labeled-audio'><p class='text'>He said the same phrase thirty times.</p>
                <audio preload='metadata' controls><source class='select-speaker' src='samples/mp3/ted_speakers/BillGates/sample-1.mp3' type='audio/mpeg'></audio>
            </div>
        </div>
      -->
    </div>

    <hr>
</body>
</html>

<script>
document
    .getElementById('select-speaker')
    .addEventListener('change', function () {
        'use strict';
        var targets = document.getElementsByClassName("select-speaker")
        for (let i = 0; i < targets.length; i++) {
            name = "samples/mp3/ted_speakers/" + this.value + "/sample-" + i.toString() + ".mp3"
            targets[i].setAttribute("src", name)
            targets[i].parentElement.load()
        }
});
</script>
